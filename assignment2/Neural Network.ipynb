{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float64) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float64) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for 0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for 0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.000000   Loss: 2.302491, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.302451, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.302476, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 3.000000   Loss: 2.302536, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.302488, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.302381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.302578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.302424, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.302486, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.302473, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10.000000   Loss: 2.302535, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 11.000000   Loss: 2.302558, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 12.000000   Loss: 2.302561, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 13.000000   Loss: 2.302531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 14.000000   Loss: 2.302597, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 15.000000   Loss: 2.302473, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 16.000000   Loss: 2.302530, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 17.000000   Loss: 2.302513, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 18.000000   Loss: 2.302480, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 19.000000   Loss: 2.302503, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cf8779dcc8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAt6UlEQVR4nO3de5Bk91XY8e/p92Omu2e6Z3dmtbIeRiReQNhmJbDBAoMxEqEkTEkgYSoWUKUQUCVU4lCqIhFEFFUxDoQiURKLxMWjsGVDeCiUXJIwTpwE22gtS7JXsqy1LK9WO7O70zPTPdOP6dfJH/f2bO/szGzP9Oveq/Opmpp+3L73t733nvn9zv09RFUxxhgTXKFJF8AYY8xoWaA3xpiAs0BvjDEBZ4HeGGMCzgK9McYEXGTSBdiuUCjotddeO+liGGOMr3zxi19cVtW5nd7zXKC/9tprOXHixKSLYYwxviIi39ztPUvdGGNMwFmgN8aYgLNAb4wxAWeB3hhjAs4CvTHGBJwFemOMCTgL9MYYE3Ce60d/YI0K/N/fHWwfoQh8170wfXgYJdq/Zz8GK9+YzLGNCYIb3gtX3zSZY5/+Apz6m8H2kTkCx392OOXpEZxA36zBZz88wA7cefmjSfjefzaUIu3L5gb85T91n8j4j2+M7ymc/hzc+9eTOfyn/y188/8x0PV79LgF+j2lC/Drawf/vCr85jxULgytSPvSPe4d/xne9v7JlMEYP3v0/VD8+uSOv3Eevu19cNcfTK4Mu7AcfZcIpPJQLU7m+N3jpvKTOb4xfpfKQ3V5csevLnv2+rVA3yuVh8qETpTucdOFyRzfGL9LF6C6Ap3O+I/dbkFtFVLevH4t0PdKF6xGb4xfpQqgbaivjf/YtVXnt0crahboe6UKk2v6Va1Gb8xAutfOJCpr3evXoxU1C/S9UnmoTKhGX1mGcAxiU5M5vjF+l5p1fk8i/VqxQO8f6Tw01qG1Of5jV4tOi0Ksa6UxB9LNj0+iVe7xFrkF+l6pSTb9is4fGmPMwUw0ddO9x2aB3vu6J8qkmn4ePUmM8YVu2mQi12830M+O/9h9sEDfq3uiTKrp59H8njG+EE1CND25m7GJLISj4z92HyzQ9+rWqCdxQ7ZS9Gx+zxjfSE9oLIzHW+QW6HtNKsfX2nRuAnv4RDHGF1ITGgtT9XZFzQJ9r0QOJDT+1E33xLSbscYMJj2hsTDdXnMeZYG+VygEydnxN/083gfXGN+Y1FiYyrJnb8RCn4FeRG4VkZdE5JSIPLDD+/9CRF4QkedF5NMick3Pex8QkZfdnw8Ms/AjMYkawdaoOu/WCIzxhe7EZqrjO6aq/1M3IhIGHgZuA44B94jIsW2bfQk4rqo3An8G/Jb72Vng14DvBm4Gfk1EZoZX/BFIuRMjjVP3eB4+UYzxhXQBWnVoVsd3zM0ydJqerqj1U6O/GTilqq+oagN4FLijdwNV/Yyqdr/ZzwNH3cc/Ajylqiuqugo8Bdw6nKKPyCTu2lesRm/MUKQmMBbGBzPP9hPorwJe63l+xn1tNz8PfGo/nxWR+0TkhIicuHBhQgt/dE1iTuvqMiCQzI33uMYEzSTGwvhg5tmh3owVkZ8BjgP7WtNPVR9R1eOqenxubm6YRdq/buqm0x7fMbs3ckLh8R3TmCBKT2AsjA86U/QT6F8Hru55ftR97RIi8h7gV4HbVXVzP5/1lHQBUKitje+YHu+aZYxvbNXoxxjot7pHe/ca7ifQPw3cICLXiUgMuBt4rHcDEXkb8BGcIH++560ngPeKyIx7E/a97mveNammn4dPEmN8Y2vQ4zivX+/fY7tioFfVFnA/ToB+Efikqp4UkYdE5HZ3sw8DU8CfisizIvKY+9kV4Ddw/lg8DTzkvuZdk5gYyeN9cI3xjXgGQtHxX7+RJMRS4zvmPkX62UhVHwce3/bagz2P37PHZz8KfPSgBRy7SdUIUu8c3/GMCSqR8Xeo8EGL3EbGbjfuOek7bWe9SY+fKMb4RnrMY2GqRU/fiAUL9JfbWo5sTIG+tgba8XR+zxhfSY15LEzF+1OMW6DfLhJ38nzjavp5fFFhY3xn7KmbZc+3yPvK0ftBZbPFf3jqawPtIxwW7n3ntSyMs0bQM3PlH3/uVb5ZHOPQbWMC5ofecph3pMc8VXHF6R79d6eW+duvnr/y9ns4kkvyc9933ZAKdlFgAv1mq8PH//70QPuoNNpkElF+aZwnivsHZT2U49/81Uli4RDRsC0Qbsx+1Zptnjuzxp/+wwLUS9Bujn7Fp2YNmhVI5/nwky/x/JkSicjBEyU3Hs1ZoN/LbDrGyYcGm0bnrQ89yWKp5jT9ymMa1+U2Mc+10wD8zk99Jz9245HxHNuYAPnlR7/EiW+uXlzXoVqE6fnRHrRn+oPFtTrve9tV/Pu7vnO0xzwAy9H3mM8kWCrVnRuj47oZ6x7nTMPpg7uQTYznuMYEzHw2yblynU5yjGNh3GO0E3nOr9c9e/1aoO+xkE2wWKo7NYJxzWldLUJsmsUN51jz2eToj2lMAC1kEzTbSjmUdV4YR/rVbZGvSoaOwrwFeu9byCWdQJ8qQLsBjY3RH7S6DOk8i2s1QgKHpuOjP6YxAdStTZ9rTzkvjKPnjdtff6nlHPOIRytqFuh7LGQSrFQaNOPu2ijjavqlCiyW6sxNx4mG7b/EmINYcIPs2YZzv2ss6Vc3Rpx1U69Wo/eB7n/SKhnnhXE1/VJ5lsp1S9sYM4Du9ftazW0Vj6VGvwwS5nTV6d1jOXofOJJzAu25zrTzwjhq9NUVSDs1+iMePUmM8YN8OkYsHOLseguSM+OpqFW6FbUGyWiYbHLE3TkPyAJ9j26NoNsMG/mJogqVZTTl5Oi92uwzxg9CIeFwNu52kS6MqaJW3KqoLWQTiHhzDIwF+h7zGSfQnq67KZRRN/0aG9DeZDM+Q6XR9myzzxi/WMi4HSrGNejRndBsseTtipoF+h7peIRMIsJrGyEIx0dfI3D3v+beE7AcvTGDmc92x8KMaRqTbuqmVLdA7ydHckkWy5vjqRG4XbMuuPcELEdvzGAWck6g11R+bJ0pOqkC59Y3Pdu1EizQX2Y+m7g4DcLIA71T41hspreObYw5uIVMgka7Qy3q3oztdEZ3sHYLamtUIznaHfX09WuBfpuFcTb93P2f2UwhAoemvXuiGOMH3fRnSTKgbaivje5gtVVAWcVpkXv5HpsF+m3mM0mWNxq0k2OY09rd/6vVJIWpOLEBZr0zxlwMtsvqdpEeZavcvX6X3dSr1eh9ZCHn/GdVIrnRj6yrFiEc4xvrYvl5Y4age/2ea7mjY0cZ6N0W+aLHpz8AC/SX6dYISpKFxjq0Nkd3MHfBgqXypqdrA8b4RSEdJxISzmxNgzDCVrn7R+TMZpJ4JEQu5c3BUtBnoBeRW0XkJRE5JSIP7PD+LSLyjIi0ROTObe99SES+4v781LAKPirdQF/U7sRII276pZ2uWQserg0Y4xehkHA4k+Cbte6gx1EGejf1Wkt6erAU9BHoRSQMPAzcBhwD7hGRY9s2Ow3cC3xs22f/EfB24K3AdwMfFJHMwKUeoe7NnK0Z8EZZI6gs00rMsr7Zshq9MUNyJJfgVCXmPBnp9etUAr++Eff89dtPjf5m4JSqvqKqDeBR4I7eDVT1VVV9Htjel+kY8FlVbalqBXgeGGwZqBGbikeYTkQ4szmOGkGRWiQHePuOvTF+Mp9NcrqsEE1vjVUZieoyJLKcKbc8nZ+H/gL9VcBrPc/PuK/14zngVhFJiUgBeDdw9faNROQ+ETkhIicuXLjQ565HZyHb2/Qb5YlSpBzKucf09olijF90FxDS9Ih7zlWLaKrAubK3R8XCiG/GquqTwOPA3wEfBz4HtHfY7hFVPa6qx+fm5kZZpL7MZ5N8vepOdTqqpl9rEzbLrLjTH1iN3pjhmM8kaLQ6tBMjHgtTWaYVn6HVUc9fv/0E+te5tBZ+1H2tL6r6m6r6VlX9YUCAr+2viOO3kEnwcjkKEhpdjcC9yXvBXRT8UMZWljJmGI64XSxr0dzIa/TVqLNIkdfnqeon0D8N3CAi14lIDLgbeKyfnYtIWETy7uMbgRuBJw9a2HFZyCW4UGmiydnR1QjcQH+2maYwFSceCY/mOMa8wXSD7nooO9rUa2V5a31a39foVbUF3A88AbwIfFJVT4rIQyJyO4CI3CQiZ4C7gI+IyEn341Hg/4jIC8AjwM+4+/O0hWwCVWglZkfXvdL9A3K6nvL8SWKMn3Svp1XJjK6ipgrV4tZqdF6/hiP9bKSqj+Pk2ntfe7Dn8dM4KZ3tn6vj9LzxlW6NoBbNER1VoHf3+0o1yfwhb58kxvhJYcoZNLXcmYZWDRoViKWHe5DNMnSaXGiniUVCzKZjw93/kNnI2B10pyPYCOdGVyNw9/vyRsymPzBmiMLuoKml5ghHx3YXBW9OeX6wFFig39Eli4SP8GasIrxWT3j+Ro4xfjOfTfDa5giXBHX3eXozubUynZdZoN/BdCLKVDziNP1qq9C5rEfo4KrLdBIzdAh5Pr9njN/MZxN8o9ZdEnR0gf6VatIX168F+l3MZ92mn3agtjb8A1SW2YzNbh3LGDM8R7IJXt4Y4VgYd5/O9Afeb5FboN/FQjbBa40RToNQLVKJOF2zvD582hi/mc8mL+boR3L9Ovs8157a6rfvZRbod7GQTfCNqvsfOIoaQbXorIKDDZYyZtgWsgnKpNBQdDSpm8oynXCCGgnL0fvZfDbJN2ruf+CITpSiZsinYySiNljKmGFy0qFCIzYzooraCpsxZ1SsH+apskC/i4VsgmLHnVF52E2/TgdqK5xrT1l+3pgR6KZDq9HciG7GLlN1Z571wzVsgX4XC9nE1qK/Q19SsL4G2uH1RsoXtQFj/GZuOk44JJRHNTq2skwplCUWDpH3+GApsEC/q4VskgZRmpGp4dfo3RPvmzV/dM0yxm/CIeHQdNyZHXZENfqiTnM4GycU8vZgKbBAv6tuc6wWyQ3/RHH/cJxppH3R7DPGj+azCc63R1BRA6iucL49xULGHy1yC/S7yCQipGJhyuHs8Jt+7v5WdNpq9MaMyJFskrPNNNRL0G4Ob8fNOjQ2eL2R8k1FzQL9LkSEhWyCFZ0efo3AbSE4gd4fNQJj/GY+m+C1end07BCnK3bjwelaigUf9KEHC/R7WsgmOd+ZHv7NWPdEWSFjNXpjRmQhm2CpNeU8GWZlzW2Rn+9MseCDPvRggX5P89kES420UwNXHd6OK0Ua4TQNor5p+hnjNwvZ5NZSnUNNv/a0yP0w/QFYoN/TkWyC1xpJaG9CY2N4O64usx7OMmuDpYwZmflsgqKOYCxMN9CT8cX0B2CBfk/z2eTFE2XINYISGV8MnTbGrxayCVbVHQszzBy9GwuKmvFNi9wC/R4WLqkRDDFPX1nmgvW4MWakDk3HKYmbox9qRW2ZDmGqoTSFtD/mqbJAv4f5S2oEQwz01SJLTetDb8woRcIh8tNpKuEhLyBULVIJZziUSflisBRYoN/TkWyS4tY0CEM6UVTRyjKLrSmO5PxxI8cYv5rPJpxZYodZo68ssyb+yc+DBfo9ZZIRqhFnhrqh1QgaFaS9yapOW47emBFz0q/TQ2+RL3f80+MG+gz0InKriLwkIqdE5IEd3r9FRJ4RkZaI3Lntvd8SkZMi8qKI/J54fRXdHiJCNpOjKdHh1Qi2+tBbjt6YUZvPJjjXmkKHGOi7LXI/Xb9XDPQiEgYeBm4DjgH3iMixbZudBu4FPrbts+8Evhe4Efh24Cbg+wcu9RjN55LODHjDumvvDr7y0x17Y/zqSDbJ+fYUOsTUjVaLFDtTvmqR91Ojvxk4paqvqGoDeBS4o3cDVX1VVZ8HOts+q0ACiAFxIAqcG7jUY7TQ7WI5rNSNu59Vm/7AmJGbd6cbl2rRWQdiUJ02Ulv1VR966C/QXwW81vP8jPvaFanq54DPAIvuzxOq+uL27UTkPhE5ISInLly40M+ux2Yhm+DcMGsEbhOymZglGbPBUsaMkjNfVQbRNmyWBt9hdQVBKfpoVCyM+GasiHwL8BbgKM4fhx8UkXdt305VH1HV46p6fG5ubpRF2rd592ZOe2NIf4DcPxixzKHh7M8Ys6uFXO+gxyHk6bv32NRf81T1E+hfB67ueX7Ufa0f7wM+r6obqroBfAp4x/6KOFnd0XUyrBx9dZkmEbLZmeHszxizq0PT8YsrxQ0j/eq2yEuSoTDlj8FS0F+gfxq4QUSuE5EYcDfwWJ/7Pw18v4hERCSKcyP2stSNl3Vz9OHmOrQ2B99hpcgqGRZmUoPvyxizp2g4hKbyzpNhpF/dfUi6QNgng6Wgj0Cvqi3gfuAJnCD9SVU9KSIPicjtACJyk4icAe4CPiIiJ92P/xnwdeDLwHPAc6r6P0fw7xiZhWzi4gx4Q+ii1a4ss9yZ9s30psb4XXTaTQcPo4ul2yqI+iz1GulnI1V9HHh822sP9jx+Giels/1zbeCfDFjGicqlopRDWedJZRkyRwbaX2v9gnsjxwK9MeOQys3DKsNJ3bh5/tSMvwK9jYy9AhEhlHabfkOoEWhl2V1wxD937I3xs/xMlqrGh3IzVqvLlDXF4ezUEEo2Phbo+xCddv96DyHQh2tFZwlBH/XBNcbPnPTrNM318wPvq1l2WuQLPpunygJ9H1I5N9APejOn1SDa2nBWprEcvTFj0V2ApFEevIt0Y/2CL5cAtUDfh8zsHG0VOpUBTxS3RVCN5kjH+7o9YowZ0JFckhWdpjOEXjdaucCKD6cvsUDfh/mZKdaYol4aNNC7J1qqMHihjDF9mc84PedCtWGkXldZ0WmO+OwemwX6PixknGHUjfKAOT63RhGZtkBvzLgcziRY0WlimwMOelQl3lhhVTLMTftnsBRYoO/LvHszpzPoNAhu6iaR9VfXLGP8LBYJUY/NEO1sQqN68B1tlglri0ZsxleDpcACfV+6a8eGaoPVCJruH4r0zMIwimWM6Vd3dOwgfendFrn6MPVqgb4Ps+kYJckQ3VwdaD/V1XN0VJgpWI3emHEKpd3RsYPckHXnu4r6MPVqgb4PIkIjPkOyVRpoTuv62jnWSDOfSw+xdMaYK4lnBp8GQd1edzEfpl4t0Pepk8wTogO1g9fqWxvLvpve1JggSM/OA1AvHbxDRW3N+ezUzPxQyjROFuj7FE67zbUBcnxSLVIk46sFC4wJgkzeCc4bK0sH3sfGqvPZbOHwUMo0Thbo+xR3m2udjYMH+kh9hXIow5QNljJmrAr5OZoa3qqVH0S9dJ66Rjk0mx9iycbDAn2fUjPOX/H11YPXCBKNVRoxW3DEmHFbyKVYHXC+m9b6BYpkfDfPDVig71sm73SJXC8eMNB3OqQ7ZVoJ/9UGjPG7w9k4RZ1GB5mYsOJMSOi3wVJggb5v+Tkn0NfWzh1sB/U1wnQQH/bBNcbv4pEw6+Es4QHGwkQ2i1TCWaJh/4VN/5V4QubzWdY1SXP9YDn67vQJ0Yy3Fj835o2iHp0h0Th4oE801qjHZodYovGxQN+n2VSMVaa3+tLu1+ryIgDJnP/64BoTBK34LOl26cCfn2qv0U5YoA+0UEhYD+cO3PQru7n96Vn/9cE1JhDSBaZ1A9rNfX9UmzVS1CHtz9SrBfp9qEdzxBsHGzBVXXVy+7NzNs+NMZMQdqcuqB5g0NSGe/3Gpv2ZerVAvw+txCyp9tqBPrtZck6UwuHBFhc3xhxMIut0kS6eP7vvzxbPO6nXhE9Tr30FehG5VUReEpFTIvLADu/fIiLPiEhLRO7sef3dIvJsz09dRH58iOUfK03lyXXKdNr7n++mXSlS0QTTU9MjKJkx5kqmZ51AX1refxfp0vJZdx/+TL1eMdCLSBh4GLgNOAbcIyLHtm12GrgX+Fjvi6r6GVV9q6q+FfhBoAo8OXixJyM8NUdcmqyW9p++CVWLlEPZEZTKGNOPXMFJm3bTMPvRTb3mfJp67adGfzNwSlVfUdUG8ChwR+8Gqvqqqj4P7FXVvRP4lKoOMPP/ZHUXDFk+9/q+PxvbXKEazQ25RMaYfs3OOWnTbhp1Pzbd7tH5OX+mXvsJ9FcBr/U8P+O+tl93Ax/f6Q0RuU9ETojIiQsXBl+pfVSm3Gbb6gGafsnmKo24P7tmGRMECXcMS2t9/zGmvbFMixDRtD+v4bHcjBWRBeA7gCd2el9VH1HV46p6fG7Ou3e1swUn0Ff2Od9Ns91hWst0kv48SYwJhHCEdZnaWkBkP6RaZEMyEPJn/5V+Sv06cHXP86Pua/vxk8BfqOr+O7B6SC7vNNvq+5wB73y5Tp7yxVVujDETUYnkiNT3H+hjmytUIrnhF2hM+gn0TwM3iMh1IhLDScE8ts/j3MMuaRs/CaWdCcla+5yq+HyxSEKaxGz6A2MmajM2Q7K5/0CfbJZoxv078+wVA72qtoD7cdIuLwKfVNWTIvKQiNwOICI3icgZ4C7gIyJysvt5EbkWp0Xwv0dQ/vGKT9Mksu91J7t9cFM+XJnGmCBpJ/JkOmVqjXbfn1mvN8lqiXbSvzPP9rUChqo+Djy+7bUHex4/jZPS2emzr3Kwm7feI8JGJEd0c381gvUV5y5/Ju+/lWmMCRJJ55ldfpalcp3rCv2t3bxUqpOXMqUpf05/ADYydt82Y7MkGquoat+f6U5tnMpZoDdmkqKZQ8ywzuJa/728F1cr5KgQy/hzVCxYoN+3dmKGHGVWq/3fV+6uaiM+nRDJmKBI5g4TlTbF5f47VKwunyMkSsqn0x+ABfp9k3SBWdY5u1br+zNb68zaoiPGTFR3CoPSPlaKK60sXvJZP7JAv0/R6UPMSpmlUr3vz4RrK7QkAnGb58aYSerOPlnZx0pxNXf6g4hPZ64EC/T7lswdIiM1zq2V+9q+1e6QaK5Si86AyIhLZ4zZk9tFurmPqYob3ZG0Pm6RW6Dfp+4N1X6bfhc2NpmhTMumPzBm8txg3d7HWBjdcBcUT/m3e6UF+n0KuV2sqiv9Nf3Orjlds9THJ4kxgeFeh6Fase+PhOrde2z+vYYt0O+XWyPozmZ3JUulOjOsE/ZxH1xjAiOWohlKkGiuUW9eedDUxmaLdKvEZngKIrExFHA0LNDvl9tFstNn02+xVCMv61ur2xhjJqsRn2VWypwrX7lDRXewVNOni4J3WaDfr27zrVrsa9DUudV1MlK1eW6M8YhOMk+edc6uXTnQL5ZqzLCO+nj6A7BAv3/JGRQhoyXW+hg0VXG7ZtlgKWO8ITw153SRLl95LMxiqU5e1gn7uGslWKDfv1CYRixHnjKLffSlr3W7cfn4Ro4xQRLLFJiV9b6u36VSnVkpE/d5i9wC/QF0UnlmZb2vGsHWajZWozfGEyLTh8jLel+DHhfXnHts4SkL9G844bRTI7hSjq/d0YvduHw82MKYQEnlSbLJ8sraFTddXSsSpeX7FrkF+gOITs8xy5WnQbiwvklO3RG0VqM3xhvca7HWxyLhm93V5Hx+/VqgPwBJFyiErpzjWyzVmJV1FIGkf1enMSZQ3Np5s49FwpsBmP4ALNAfTCpPlg3OlSp7brZUqjNLmXY8B6HweMpmjNmbG7TDtRU2W7sPmqo2WsQb7iJDlrp5A0oXCNNhY23vQVNn3Tv21rXSGA9xr8dZypwrbe662WKpzqysu5+xQP/G49YIGuULew6aWirVKITWt+bHMcZ4gFs7n5Uyi6Xde845LXI30Fvq5g3I/euebq1RrrV23WyxVOdQqIL4vNlnTKAksmgo4naR3v0+26LbIu+EExDrb31Zr7JAfxC9NYI9+tJ3B1v4/Y69MYEigibzzLJ3h4old54qSc36fi2JvgK9iNwqIi+JyCkReWCH928RkWdEpCUid257700i8qSIvCgiL4jItUMq++S4zbhZWWdxj770S2tVpjrrvm/2GRM0oXSBw5F1FvdYEvRsqc7h8EYg7rFdMdCLSBh4GLgNOAbcIyLHtm12GrgX+NgOu/gj4MOq+hbgZqD/pV28autmzu41gnZHqa2vEKZtNXpjvCad51C4coUafZ1D4Y1AXL/91OhvBk6p6iuq2gAeBe7o3UBVX1XV54FO7+vuH4SIqj7lbrehqtXhFH2CInE0Nk1ByiztcjOnuLFJVkvOE8vRG+MtqbwzDUIfOfogtMj7CfRXAa/1PD/jvtaPbwXWROTPReRLIvJht4VwCRG5T0ROiMiJCxeuPIjBCyQ1y5HY7jWCRbcPPWCB3hivSRXIaumKOfpMpxSI63fUN2MjwLuADwI3AdfjpHguoaqPqOpxVT0+N+eTyYPShT2bft0FR7rbGmM8JF0g1V5nbaNCo9W57O1ao021WiHeqfm+Dz30F+hfB67ueX7Ufa0fZ4Bn3bRPC/hL4O37KqFXpQrkQ7v3w10s1ZmRYPTBNSZw3Fp6Vis7rjS1VHaWAHW29f/120+gfxq4QUSuE5EYcDfwWJ/7fxrIiUi3mv6DwAv7L6YHpQtkO86c9DsNmloq1TkU6p4o/q8RGBMoPV2kd8rTB61FfsVA79bE7weeAF4EPqmqJ0XkIRG5HUBEbhKRM8BdwEdE5KT72TZO2ubTIvJlQIDfH80/ZcxSs6Tba1QbLcr1ywdNnS3VORqvQmwKookJFNAYsys3eOelzNkdulgurrk3YiEQFbVIPxup6uPA49tee7Dn8dM4KZ2dPvsUcOMAZfSmVIFIp0GKTZZKdbLJ6CVvL5VqLEQ2IOH/k8SYwEld7CK903Tjb8TUjdlJty/9LvNlLJbqFALSB9eYwHGvy4Xozh0qFks1jsYrl2zrZxboD8r9K5/fYQGSTkc5V64zQzkQzT5jAsddH+LqRHXnGn2pztXxGkgIErkxF274+krdmB24ATwfWufsthNlubJJs61Mt0uBaPYZEzjhKCRyHIlUdmyRn12rO6nX0CyE/F8f9v+/YFLcvrXXJGqXjY51aghKorEaiD64xgRSusCh0MaOqZulcrBSrxboD8qtqb8pXr3sRFks1UmySbizaTV6Y7wqVWBGylzY2KTZvjhoqt5ss1JpMKPBmP4ALNAfXHwawjGOxC7P8S2V6hf74FqO3hhvSuXJdEqowvn1iytNdQdQTXdKgWmRW6A/KBFI5TkUvnwGy7OlGofDG86TgDT9jAmcdJ5kcw3gkumKz7pTjyebq4GpqFmgH0SqwAzrbGy2WK83t15eKtW5Pl3b2sYY40GpArHGKqCXVNaWyjVCdIhsrgXm+rVAP4i00/QDLknfLJbqXJOob21jjPGgdAHptMhQvez6zbGBoIFpkVugH0SqQKq1BnBpjaBU52jMHWwRkKafMYHjXptHt3WoWCrVuSZRvWQbv7NAP4hUntjmCsBWX9xOR1kq1Tkc2YBQFOKZSZbQGLMbNy3zLen6JX3pz67V+ZYpN/BboDekC4Qa68SktVUjWKk2aLQ7Tq+bdMH3iwobE1huWvW6VO2yHP3F1Kulboz71/7N6c2tHF/3d47g9ME1JpDc6/OqbV2kl0p1ropXL9nG7yzQD8L9a3/DVH2rRtD9nW6tQWp2UiUzxlyJW1FbiFY4v16n1e6w2WqzvNFgPrJxyTZ+Z4F+EO5JcF2itpXj6/6ON1YD0+wzJpBiKYimmAut03EHTZ0rOQOnClJ27q9FYhMu5HDYpGaDcJt1RxM1Fpcu1uijYSFcKwam2WdMYKUK5NRZYGSx5NTqAbK6HpjaPFigH0zPnNbr9RYbmy2WSnWOTEeQetlq9MZ4XTrPVPviWJhWxwn0U+21QF2/FugHkZwBhDl3bdilUo2zazW+dboBdSxHb4zXpfIkNpYBJ+3abDvrP8cbq5C7epIlGyrL0Q8iFIbkDDl1agSLpTpL5TrXp7p9cINTIzAmkFIFwrUiqVjYuX5LNaYTETf1aqkb05UuMN1xc3xrTu+ba45Wt94zxnhYuoBUi8xnEyyV6jTbHRYycagUAzV9iQX6QaUKzgIjwAuLZRqtDkdiweqDa0xgpfLQrHLtnLBYqtHqKNdlFMqNQF2/faVuRORWEXlJRE6JyAM7vH+LiDwjIi0RuXPbe20Redb9eWxYBfeM1CyhWpHCVIwvnXYC/qGwzUVvjC+41+j16U0WS3XOrtV5cypY0x9AHzV6EQkDDwM/DJwBnhaRx1T1hZ7NTgP3Ah/cYRc1VX3r4EX1qHQBTn+e+WyCk2edFM6srANiN2ON8To3vXpNssq5cpSOwpsCNv0B9Fejvxk4paqvqGoDeBS4o3cDVX1VVZ8HOjvtINBSBaitsDAdp9Vx7thnOiWnR04oPOHCGWP2tDUNQgX38g1k6rWfQH8V8FrP8zPua/1KiMgJEfm8iPz4ThuIyH3uNicuXLiwj117QLoA2uH6aWfhkUhISDTXAlUbMCaw3Ot0PlLdeuni6nDBSd2Mo3vlNap6HPhp4HdF5M3bN1DVR1T1uKoen5ubG0ORhsjN43Xnrz6cSRCqBqtrljGB5aZX81LeemnrcYCu4X4C/etA78iBo+5rfVHV193frwD/C3jbPsrnfT2LFwDMZxNQWQ7USWJMYCVyEIqQdcfCgJt6DcchNjW5cg1ZP4H+aeAGEblORGLA3UBfvWdEZEZE4u7jAvC9wAt7f8pn3Kbf4bCzotR8NgHVoqVujPEDEUjliTfWSERDTMUjxBprgVtL4oqBXlVbwP3AE8CLwCdV9aSIPCQitwOIyE0icga4C/iIiJx0P/4W4ISIPAd8Bvh323rr+J97w6bgToNwJBNzAn2AbuQYE2gpZ9DUkWyShYC2yPsaMKWqjwOPb3vtwZ7HT+OkdLZ/7u+A7xiwjN7mnhBZLfGm2W/l5oUwaDtwJ4oxgZWahcoyN107SygkUHyDBnqzh2gCYlNEait89lfeDcsvO69b6sYYf0gXYOnLfOjnb3Se/+4yzF4/2TINmU1qNgypvJOugYu/A1YjMCawUoWL1y1AdSVwqVer0Q9DugBVZ6pTKssXXzPGeF+6ALVVaLectGtjPVB96MEC/XCk8rC+5DzuBnyr0RvjD91rtbYC7ealrwWEpW6Gobfp163RB6zpZ0xgdYN6Zbmnohas69dq9MOQdnP0qk5+Lzbl3KQ1xnhfN81aLUKneelrAWGBfhhSBWjVoVFxagQBa/YZE2jd2nt12cnT974WEBboh6Eb2KvLgRxsYUyg9aZuOq1LXwsIC/TD0G3mVYpOsJ86PNnyGGP61103olp0bsZKyJlmPEDsZuwwpHpyfAHsg2tMoIWjzuRm1aLzk5yFULBCo9XohyG9LXUTsD64xgReuuCmbpqBuxELFuiHo5vPW3sNWrXA5feMCbxU/uLN2ABev8Fqn0xKPAOhKFz4qvPcUjfG+EuqcPEemwV6syMRp7m3/DXneQCbfsYEWncsTEDXkrDUzbCkegK91eiN8ZeUO19Vpx3I69cC/bCkZqG9efGxMcY/UvnA9qEHS90MT29zL4BNP2MCLeDXrwX6Yek290JR5+asMcY/etM1VqM3u+rWAlL5QC0qbMwbQm+61Wr0ZlfdEyWAJ4kxgZe2Gr3pR6qnRm+M8RdL3YCI3CoiL4nIKRF5YIf3bxGRZ0SkJSJ37vB+RkTOiMh/GkahPalbI7AavTH+E0tBNOXcX4vEJ12aobtioBeRMPAwcBtwDLhHRI5t2+w0cC/wsV128xvAZw9eTB+wGr0x/pbKB/b67adGfzNwSlVfUdUG8ChwR+8Gqvqqqj4PdLZ/WES+CzgMPDmE8npX9wQJ4GALY94QAhzo+xkwdRXwWs/zM8B397NzEQkBvw38DPCePba7D7gP4E1velM/u/aedAHe/a/h239i0iUxxhzEu/6lMxd9AI16ZOwvAo+r6hnZo8uhqj4CPAJw/PhxHXGZRkMEvv9fTboUxpiDOnb7pEswMv0E+teBq3ueH3Vf68c7gHeJyC8CU0BMRDZU9bIbusYYY0ajn0D/NHCDiFyHE+DvBn66n52r6vu7j0XkXuC4BXljjBmvKyakVLUF3A88AbwIfFJVT4rIQyJyO4CI3CQiZ4C7gI+IyMlRFtoYY0z/RNVbKfHjx4/riRMnJl0MY4zxFRH5oqoe3+m9YN5iNsYYs8UCvTHGBJwFemOMCTgL9MYYE3CeuxkrIheAbw6wiwKwPKTijIKVbzBWvsFY+Qbj5fJdo6pzO73huUA/KBE5sdudZy+w8g3GyjcYK99gvF6+3VjqxhhjAs4CvTHGBFwQA/0jky7AFVj5BmPlG4yVbzBeL9+OApejN8YYc6kg1uiNMcb0sEBvjDEB58tA38di5XER+YT7/hdE5Noxlu1qEfmMiLwgIidF5J/vsM0PiEhJRJ51fx4cV/l6yvCqiHzZPf5ls8iJ4/fc7/B5EXn7GMv2D3q+m2dFpCwiv7xtm7F+hyLyURE5LyJf6XltVkSeEpGX3d8zu3z2A+42L4vIB8ZYvg+LyFfd/7+/EJHcLp/d81wYYfl+XURe7/k//NFdPrvn9T7C8n2ip2yvisizu3x25N/fwFTVVz9AGPg6cD0QA54Djm3b5heB/+o+vhv4xBjLtwC83X08DXxth/L9APDXE/4eXwUKe7z/o8CnAAG+B/jCBP+/l3AGg0zsOwRuAd4OfKXntd8CHnAfPwB8aIfPzQKvuL9n3MczYyrfe4GI+/hDO5Wvn3NhhOX7deCDffz/73m9j6p8297/beDBSX1/g/74sUZ/xcXK3ed/6D7+M+CHZK+1DIdIVRdV9Rn38TrOHP5XjePYQ3YH8Efq+DyQE5GFCZTjh4Cvq+ogo6UHpqqfBVa2vdx7nv0h8OM7fPRHgKdUdUVVV4GngFvHUT5VfVKd9SQAPo+zOtxE7PL99aOf631ge5XPjR0/CXx82McdFz8G+p0WK98eSLe2cU/0EjD25d3dlNHbgC/s8PY7ROQ5EfmUiHzbeEsGgAJPisgX3cXZt+vnex6Hu9n9Apv0d3hYVRfdx0vA4R228cr3+HM4LbSdXOlcGKX73dTSR3dJfXnh+3sXcE5VX97l/Ul+f33xY6D3BRGZAv4H8MuqWt729jM4qYjvBP4j8JdjLh7A96nq24HbgF8SkVsmUIY9iUgMuB340x3e9sJ3uEWdNrwn+yqLyK8CLeBPdtlkUufCfwHeDLwVWMRJj3jRPexdm/f8teTHQN/PYuVb24hIBMgCxbGUzjlmFCfI/4mq/vn291W1rKob7uPHgaiIFMZVPve4r7u/zwN/gdNE7jXIovDDchvwjKqe2/6GF75D4Fw3neX+Pr/DNhP9HsVZq/nHgPe7f4wu08e5MBKqek5V26raAX5/l+NO+vuLAD8BfGK3bSb1/e2HHwP91mLlbo3vbuCxbds8BnR7N9wJ/O1uJ/mwufm8/w68qKq/s8s28917BiJyM87/wzj/EKVFZLr7GOem3Ve2bfYY8I/d3jffA5R60hTjsmtNatLfoav3PPsA8Fc7bPME8F4RmXFTE+91Xxs5EbkV+BXgdlWt7rJNP+fCqMrXe8/nfbsct5/rfZTeA3xVVc/s9OYkv799mfTd4IP84PQI+RrO3fhfdV97COeEBkjgNPdPAX8PXD/Gsn0fThP+eeBZ9+dHgV8AfsHd5n7gJE4Pgs8D7xzz93e9e+zn3HJ0v8PeMgrwsPsdfxk4PuYypnECd7bntYl9hzh/cBaBJk6e+Odx7vt8GngZ+Btg1t32OPDfej77c+65eAr42TGW7xROfrt7HnZ7oh0BHt/rXBhT+f7YPbeexwneC9vL5z6/7HofR/nc1/+ge871bDv272/QH5sCwRhjAs6PqRtjjDH7YIHeGGMCzgK9McYEnAV6Y4wJOAv0xhgTcBbojTEm4CzQG2NMwP1/i+IS6skuu0kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.000000   Loss: 2.302239, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.308332, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.289100, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.306072, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.250868, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.291086, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.212819, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.325159, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.290994, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.313145, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10.000000   Loss: 2.238692, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 11.000000   Loss: 2.286604, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 12.000000   Loss: 2.355889, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 13.000000   Loss: 2.233891, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 14.000000   Loss: 2.379898, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 15.000000   Loss: 2.259309, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 16.000000   Loss: 2.315171, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 17.000000   Loss: 2.272651, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 18.000000   Loss: 2.288477, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 19.000000   Loss: 2.297109, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.000000   Loss: 2.328003, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.322595, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.320111, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.311517, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.309783, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.312030, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.305316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.305544, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.302871, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.303209, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10.000000   Loss: 2.301828, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 11.000000   Loss: 2.305645, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 12.000000   Loss: 2.297752, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 13.000000   Loss: 2.302125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 14.000000   Loss: 2.301015, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 15.000000   Loss: 2.298528, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 16.000000   Loss: 2.298850, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 17.000000   Loss: 2.294343, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 18.000000   Loss: 2.292257, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 19.000000   Loss: 2.303052, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.000000   Loss: 2.333937, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Epoch 1.000000   Loss: 2.317794, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Epoch 2.000000   Loss: 2.311414, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Epoch 3.000000   Loss: 2.317738, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch 4.000000   Loss: 2.310963, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch 5.000000   Loss: 2.295162, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch 6.000000   Loss: 2.306700, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch 7.000000   Loss: 2.312951, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch 8.000000   Loss: 2.188086, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 9.000000   Loss: 2.312709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 10.000000   Loss: 2.197881, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 11.000000   Loss: 1.849126, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 12.000000   Loss: 1.780270, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 13.000000   Loss: 2.251930, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 14.000000   Loss: 1.486206, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 15.000000   Loss: 1.866126, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 16.000000   Loss: 2.433965, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 17.000000   Loss: 2.161626, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 18.000000   Loss: 1.898055, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 19.000000   Loss: 2.410837, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 20.000000   Loss: 1.940008, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 21.000000   Loss: 2.309926, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 22.000000   Loss: 2.339107, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 23.000000   Loss: 1.937049, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 24.000000   Loss: 1.604362, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 25.000000   Loss: 1.849866, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 26.000000   Loss: 1.608855, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 27.000000   Loss: 1.799068, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 28.000000   Loss: 1.646099, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 29.000000   Loss: 1.344290, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 30.000000   Loss: 1.302868, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 31.000000   Loss: 1.937343, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 32.000000   Loss: 1.829499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 33.000000   Loss: 0.922337, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 34.000000   Loss: 1.287374, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 35.000000   Loss: 2.024106, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 36.000000   Loss: 1.356417, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 37.000000   Loss: 1.868552, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 38.000000   Loss: 1.145049, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 39.000000   Loss: 1.312459, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 40.000000   Loss: 1.853885, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 41.000000   Loss: 1.927055, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 42.000000   Loss: 1.698139, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 43.000000   Loss: 1.029793, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 44.000000   Loss: 1.263701, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 45.000000   Loss: 1.243885, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 46.000000   Loss: 1.809255, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 47.000000   Loss: 2.009188, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 48.000000   Loss: 1.976258, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 49.000000   Loss: 1.725382, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 50.000000   Loss: 1.718600, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 51.000000   Loss: 1.355265, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 52.000000   Loss: 1.756636, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 53.000000   Loss: 1.645104, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 54.000000   Loss: 1.467615, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 55.000000   Loss: 1.742957, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 56.000000   Loss: 1.662766, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 57.000000   Loss: 0.950975, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 58.000000   Loss: 1.911569, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 59.000000   Loss: 1.678126, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 60.000000   Loss: 1.407856, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 61.000000   Loss: 1.372868, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 62.000000   Loss: 2.133259, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 63.000000   Loss: 0.885455, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 64.000000   Loss: 0.904529, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 65.000000   Loss: 1.695704, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 66.000000   Loss: 1.760834, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 67.000000   Loss: 1.726174, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 68.000000   Loss: 1.362958, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 69.000000   Loss: 0.869866, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 70.000000   Loss: 1.809623, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 71.000000   Loss: 1.602223, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 72.000000   Loss: 1.435857, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 73.000000   Loss: 1.310070, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 74.000000   Loss: 1.420249, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 75.000000   Loss: 0.930928, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 76.000000   Loss: 1.023011, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 77.000000   Loss: 1.662360, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 78.000000   Loss: 0.923455, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Epoch 79.000000   Loss: 1.378719, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 80.000000   Loss: 1.017884, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 81.000000   Loss: 1.587115, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 82.000000   Loss: 1.290608, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 83.000000   Loss: 1.712042, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 84.000000   Loss: 0.941492, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 85.000000   Loss: 1.262382, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 86.000000   Loss: 1.512804, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 87.000000   Loss: 1.598327, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 88.000000   Loss: 1.359766, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 89.000000   Loss: 1.647165, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 90.000000   Loss: 1.702833, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 91.000000   Loss: 1.356661, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 92.000000   Loss: 1.504936, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 93.000000   Loss: 1.184592, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 94.000000   Loss: 1.660633, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 95.000000   Loss: 1.568945, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 96.000000   Loss: 1.184369, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 97.000000   Loss: 1.642625, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 98.000000   Loss: 1.580958, Train accuracy: 0.933333, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99.000000   Loss: 1.232451, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 100.000000   Loss: 1.129635, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 101.000000   Loss: 1.255625, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 102.000000   Loss: 1.277714, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 103.000000   Loss: 1.272459, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 104.000000   Loss: 1.544072, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 105.000000   Loss: 1.074981, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 106.000000   Loss: 1.221890, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 107.000000   Loss: 1.508199, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 108.000000   Loss: 1.265740, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 109.000000   Loss: 1.093197, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 110.000000   Loss: 1.078182, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 111.000000   Loss: 1.396701, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 112.000000   Loss: 1.196835, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 113.000000   Loss: 1.500422, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 114.000000   Loss: 1.411617, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 115.000000   Loss: 1.378281, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 116.000000   Loss: 1.541671, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 117.000000   Loss: 1.520645, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 118.000000   Loss: 1.291475, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 119.000000   Loss: 1.483820, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 120.000000   Loss: 1.092267, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 121.000000   Loss: 1.156399, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 122.000000   Loss: 1.312057, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 123.000000   Loss: 1.375706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 124.000000   Loss: 1.187760, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 125.000000   Loss: 1.178739, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 126.000000   Loss: 1.030843, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 127.000000   Loss: 1.444193, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 128.000000   Loss: 1.419100, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 129.000000   Loss: 1.049936, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 130.000000   Loss: 1.255490, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 131.000000   Loss: 1.417001, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 132.000000   Loss: 1.441178, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 133.000000   Loss: 1.260513, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 134.000000   Loss: 1.077556, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 135.000000   Loss: 1.598049, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 136.000000   Loss: 1.467817, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 137.000000   Loss: 1.271817, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 138.000000   Loss: 1.149556, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 139.000000   Loss: 1.402210, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 140.000000   Loss: 1.337246, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 141.000000   Loss: 1.566721, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 142.000000   Loss: 1.395437, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 143.000000   Loss: 1.310198, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 144.000000   Loss: 1.294743, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 145.000000   Loss: 1.253067, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 146.000000   Loss: 1.413489, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 147.000000   Loss: 1.370860, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 148.000000   Loss: 1.352736, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 149.000000   Loss: 1.274250, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0.000000   Loss: 2.304164, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 1.000000   Loss: 2.300611, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 2.000000   Loss: 2.294768, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Epoch 3.000000   Loss: 2.280846, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Epoch 4.000000   Loss: 2.226447, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Epoch 5.000000   Loss: 2.021206, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 6.000000   Loss: 1.801513, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch 7.000000   Loss: 1.818511, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 8.000000   Loss: 1.670517, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 9.000000   Loss: 1.674403, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 10.000000   Loss: 1.356496, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 11.000000   Loss: 1.244227, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Epoch 12.000000   Loss: 1.224683, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 13.000000   Loss: 1.090254, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Epoch 14.000000   Loss: 0.910803, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 15.000000   Loss: 0.791945, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 16.000000   Loss: 0.694649, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 17.000000   Loss: 0.629865, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 18.000000   Loss: 0.584942, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Epoch 19.000000   Loss: 0.549306, Train accuracy: 0.933333, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 5e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum = 0.3), learning_rate=6e-1, num_epochs=20, batch_size=120)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycle 1...\n",
      "Epoch 0.000000   Loss: 2.302630, Train accuracy: 0.114222, val accuracy: 0.147000\n",
      "Epoch 1.000000   Loss: 2.302254, Train accuracy: 0.114222, val accuracy: 0.147000\n",
      "Epoch 2.000000   Loss: 2.302047, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.301775, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.301768, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.302024, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.302057, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.302234, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.300127, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.301736, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 2...\n",
      "Epoch 0.000000   Loss: 2.304545, Train accuracy: 0.113333, val accuracy: 0.147000\n",
      "Epoch 1.000000   Loss: 2.304309, Train accuracy: 0.114444, val accuracy: 0.148000\n",
      "Epoch 2.000000   Loss: 2.304130, Train accuracy: 0.196556, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.304206, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.304134, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.304167, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.304255, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.304104, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.304178, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.303361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 3...\n",
      "Epoch 0.000000   Loss: 2.300418, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.293267, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.281079, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.236033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.194201, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.220893, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.284224, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.258611, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.228701, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.300599, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 4...\n",
      "Epoch 0.000000   Loss: 2.309401, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.306152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.291347, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.239262, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.291880, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.167090, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.180131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.268628, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.213244, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.261780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 5...\n",
      "Epoch 0.000000   Loss: 2.302418, Train accuracy: 0.144222, val accuracy: 0.134000\n",
      "Epoch 1.000000   Loss: 2.302438, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Epoch 2.000000   Loss: 2.302348, Train accuracy: 0.149000, val accuracy: 0.140000\n",
      "Epoch 3.000000   Loss: 2.302499, Train accuracy: 0.197444, val accuracy: 0.209000\n",
      "Epoch 4.000000   Loss: 2.302170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.301551, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.301776, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.302240, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.301707, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.300872, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 6...\n",
      "Epoch 0.000000   Loss: 2.302693, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 1.000000   Loss: 2.302581, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 2.000000   Loss: 2.302159, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 3.000000   Loss: 2.302325, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 4.000000   Loss: 2.302342, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 5.000000   Loss: 2.302786, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 6.000000   Loss: 2.302254, Train accuracy: 0.062222, val accuracy: 0.060000\n",
      "Epoch 7.000000   Loss: 2.302301, Train accuracy: 0.062222, val accuracy: 0.060000\n",
      "Epoch 8.000000   Loss: 2.302571, Train accuracy: 0.063444, val accuracy: 0.060000\n",
      "Epoch 9.000000   Loss: 2.302226, Train accuracy: 0.064667, val accuracy: 0.065000\n",
      "\n",
      "Cycle 7...\n",
      "Epoch 0.000000   Loss: 2.302544, Train accuracy: 0.098000, val accuracy: 0.098000\n",
      "Epoch 1.000000   Loss: 2.302497, Train accuracy: 0.195889, val accuracy: 0.208000\n",
      "Epoch 2.000000   Loss: 2.302577, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.302046, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.302537, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.302208, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.301853, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.301568, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.302001, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.301680, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 8...\n",
      "Epoch 0.000000   Loss: 2.302131, Train accuracy: 0.186444, val accuracy: 0.195000\n",
      "Epoch 1.000000   Loss: 2.301744, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.302229, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.301801, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.301043, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.301293, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.300893, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.301514, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.300359, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.301269, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 9...\n",
      "Epoch 0.000000   Loss: 2.300659, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.301377, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.302606, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.281936, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.272836, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.238502, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.231035, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.317338, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.245917, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.296742, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 10...\n",
      "Epoch 0.000000   Loss: 2.299224, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.254629, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.305758, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.190858, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.241348, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.250864, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.223320, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.165946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.151021, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9.000000   Loss: 2.077981, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 11...\n",
      "Epoch 0.000000   Loss: 2.302465, Train accuracy: 0.099000, val accuracy: 0.093000\n",
      "Epoch 1.000000   Loss: 2.302379, Train accuracy: 0.099000, val accuracy: 0.093000\n",
      "Epoch 2.000000   Loss: 2.302036, Train accuracy: 0.111667, val accuracy: 0.099000\n",
      "Epoch 3.000000   Loss: 2.302155, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.301525, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.302058, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.301061, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.300715, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.301486, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.301106, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 12...\n",
      "Epoch 0.000000   Loss: 2.302559, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 1.000000   Loss: 2.302635, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 2.000000   Loss: 2.302223, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 3.000000   Loss: 2.302609, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 4.000000   Loss: 2.302864, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 5.000000   Loss: 2.302577, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 6.000000   Loss: 2.302407, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 7.000000   Loss: 2.303001, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 8.000000   Loss: 2.302568, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "Epoch 9.000000   Loss: 2.302599, Train accuracy: 0.062333, val accuracy: 0.060000\n",
      "\n",
      "Cycle 13...\n",
      "Epoch 0.000000   Loss: 2.304380, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.304252, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2.000000   Loss: 2.304155, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3.000000   Loss: 2.303791, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4.000000   Loss: 2.304225, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5.000000   Loss: 2.304008, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6.000000   Loss: 2.304263, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7.000000   Loss: 2.303690, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8.000000   Loss: 2.303845, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 9.000000   Loss: 2.304347, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 14...\n",
      "Epoch 0.000000   Loss: 2.224209, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 1.888345, Train accuracy: 0.291667, val accuracy: 0.299000\n",
      "Epoch 2.000000   Loss: 1.537040, Train accuracy: 0.402889, val accuracy: 0.408000\n",
      "Epoch 3.000000   Loss: 1.436396, Train accuracy: 0.553889, val accuracy: 0.553000\n",
      "Epoch 4.000000   Loss: 1.109844, Train accuracy: 0.628000, val accuracy: 0.627000\n",
      "Epoch 5.000000   Loss: 1.098460, Train accuracy: 0.624889, val accuracy: 0.604000\n",
      "Epoch 6.000000   Loss: 1.102120, Train accuracy: 0.684222, val accuracy: 0.663000\n",
      "Epoch 7.000000   Loss: 1.077316, Train accuracy: 0.709222, val accuracy: 0.676000\n",
      "Epoch 8.000000   Loss: 1.096395, Train accuracy: 0.705778, val accuracy: 0.659000\n",
      "Epoch 9.000000   Loss: 0.593572, Train accuracy: 0.764444, val accuracy: 0.712000\n",
      "\n",
      "Cycle 15...\n",
      "Epoch 0.000000   Loss: 2.312675, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1.000000   Loss: 2.153864, Train accuracy: 0.197556, val accuracy: 0.205000\n",
      "Epoch 2.000000   Loss: 2.189116, Train accuracy: 0.242000, val accuracy: 0.243000\n",
      "Epoch 3.000000   Loss: 2.015204, Train accuracy: 0.309889, val accuracy: 0.311000\n",
      "Epoch 4.000000   Loss: 1.875384, Train accuracy: 0.379889, val accuracy: 0.383000\n",
      "Epoch 5.000000   Loss: 2.125798, Train accuracy: 0.430111, val accuracy: 0.444000\n",
      "Epoch 6.000000   Loss: 1.964890, Train accuracy: 0.500333, val accuracy: 0.495000\n",
      "Epoch 7.000000   Loss: 1.853091, Train accuracy: 0.516667, val accuracy: 0.504000\n",
      "Epoch 8.000000   Loss: 1.782724, Train accuracy: 0.528778, val accuracy: 0.534000\n",
      "Epoch 9.000000   Loss: 1.822024, Train accuracy: 0.566222, val accuracy: 0.553000\n",
      "best validation accuracy achieved: 0.712000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "from random import choice\n",
    "\n",
    "n_iterations = 15\n",
    "num_epochs = 10\n",
    "learning_rates = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "reg_strength = [1e-6, 1e-4, 1e-2]\n",
    "learning_rate_decay = [0.888, 0.995, 0.999]\n",
    "hidden_layer_size = [64, 128, 256]\n",
    "batch_size = [64]\n",
    "momentums = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "for i in range(0, n_iterations):    \n",
    "    lr = choice(learning_rates)\n",
    "    reg = choice(reg_strength)\n",
    "    lrd = choice(learning_rate_decay)\n",
    "    hs = choice(hidden_layer_size)\n",
    "    bs = choice(batch_size)\n",
    "    momentum = choice(momentums)\n",
    "    \n",
    "    model = TwoLayerNet(n_input=train_X.shape[1], n_output=10,\n",
    "                        hidden_layer_size=hs, reg=reg)\n",
    "    dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "    trainer = Trainer(model, dataset, MomentumSGD(momentum=momentum), learning_rate=lr,\n",
    "                      learning_rate_decay=lrd, num_epochs=num_epochs, batch_size=bs)\n",
    "    \n",
    "    print()\n",
    "    print (\"Cycle {}...\".format(i+1))\n",
    "    loss_hist, train_hist, val_hist = trainer.fit()\n",
    "    \n",
    "    if val_hist[-1] > best_val_accuracy:\n",
    "        best_val_accuracy = val_hist[-1]\n",
    "        best_classifier = model\n",
    "        \n",
    "        best_params['learning_rate'] = lr\n",
    "        best_params['reg_strength'] = reg\n",
    "        best_params['learning_rate_decay'] = lrd\n",
    "        best_params['hidden_layer_size'] = hs\n",
    "        best_params['batch_size'] = bs\n",
    "        best_params['momentum'] = momentum\n",
    "        \n",
    "        loss_history = loss_hist\n",
    "        train_history = train_hist\n",
    "        val_history = val_hist\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cf8792a3c8>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.666000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
